{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequency\n",
    "임의의 text file에 있는 word들의 빈도수를 구하려 한다. word는 대소문자 구분없고 숫자, 특수 문자들은 단어에서 배제된다.\n",
    "따라서, word들의 list를 만들기 전에 file을 읽고 난 후\n",
    "- 대문자는 소문자로 변환\n",
    "- 숫자, 특수문자는 `' '` 로 변환해야 할 것이다.\n",
    "\n",
    "#### Hint:\n",
    "주어진 text를 한 번 scan으로 효율적으로 변환해 주는 string method를 사용하면 될 것이다.\n",
    "`maketrans` method는 변환시키는 dictionany를 정의해 주고, `translate` method는 이를 가지고 변환한 새로운 string을 generate한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " well  i never    said alice \n"
     ]
    }
   ],
   "source": [
    "the_text = '\"Well, I never!\", said Alice.'\n",
    "my_substitutions = the_text.maketrans(\n",
    "  # If you find any of these\n",
    "  \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\\\"#$%&()*+,-./:;<=>?@[]^_`{|}~\\\\\\r\\n\",\n",
    "  # Replace them by these\n",
    "  \"abcdefghijklmnopqrstuvwxyz                                           \")\n",
    "\n",
    "# Translate the text now.\n",
    "cleaned_text = the_text.translate(my_substitutions)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input: \n",
    "인터넷에 있는 *Alice in Wonderland* 동화책 내용을 다음과 같이 fetch한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "url = \"http://openbookproject.net/thinkcs/python/english3e/_downloads/alice_in_wonderland.txt\" \n",
    "with urllib.request.urlopen(url) as f:\n",
    "    contents = f.read().decode()\n",
    "url_word = \"http://openbookproject.net/thinkcs/python/english3e/_downloads/vocab.txt\" \n",
    "with urllib.request.urlopen(url_word) as f:\n",
    "    word_contents = f.read().decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_contents = contents.translate(my_substitutions)\n",
    "new_word_contents = word_contents.translate(my_substitutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 방법\n",
    " 's 'd 는 is, has 와 would, had 와 구분이 어렵기 때문에 모두 한 단어 처리하였습니다.--done    \n",
    "   \n",
    " 'tis 는 it is의 영국식 줄임말이기 때문에, it, is 두 단어로 처리하였습니다.--done  \n",
    "   \n",
    " shan't는 shall not의 영국식 줄임말이기 때문에, shall, not 두 단어로 처리하였습니다.--done  \n",
    "   \n",
    " ~n't형은 최대한 ~과 not으로 구분하였습니다.--done  \n",
    "   \n",
    "또한, chapter를 셀때 사용한 로마문자 (I, II, III, IIII, V...XI)는 단어에서 제거하였습니다.--done  \n",
    "  \n",
    "I 같은 경우에는 \"나\"를 뜻할때도 많이 사용하기 때문에, 최종으로 나온 I count에서 -1 하였습니다.--done  \n",
    "  \n",
    "'em 은 them 의 줄임말이기 때문에 them으로 편입하였습니다.--done  \n",
    "  \n",
    "내용중 beau---ootiful은 beautiful로, soo--oop는 soup로,  e--e--evening은 evening으로,  동일한 패턴의 반복이므로 합쳐서 한 글자로 처리하였습니다.--done  \n",
    "  \n",
    "ied 과거형을 y로 변경했습니다. tie, die 같은 경우에는 ty, dy 로 없는 단어가 되어 tie, die로 바꾸어주었습니다.--done  \n",
    "  \n",
    "ed와 ing를 사용하기 위해서 사전에 제공해주신 단어장을 이용하였습니다. 완벽하지는 않으나, 어느정도 단어개수를 줄여줄 수 있을것으로 예상됩니다.  \n",
    "  \n",
    "ied 과거형을 y로 바꾸었습니다.--done  \n",
    "  \n",
    "ed 과거형을 현재형으로 최대한 바꾸었습니다.--done  \n",
    "  \n",
    "ed/d가 붙음으로인해 동사인지 형용사인지 혼동되는 부분이 있어서, 이부분에 대해 확실하게 구분을 하지 못했습니다.  \n",
    "  \n",
    "ed가 붙는 경우 사전에 주어진 단어장을 통해 형용사 먼저 단어에 추가하였습니다.  \n",
    "  \n",
    "순서: 형용사 -> ied -> ed -> ~d 순서대로 걸렀습니다.\n",
    "  \n",
    "ing 진행형을 현재형으로 최대한 바꾸었습니다.--done  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = new_contents.split(\" \")\n",
    "word_list = new_word_contents.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import string\n",
    "save,align_word, buff = 'a', [], []\n",
    "for word in word_list:\n",
    "    if word is not \"\":\n",
    "        if save != word[0]:\n",
    "            align_word.append(copy.copy(buff))\n",
    "            buff.clear()\n",
    "        save = word[0]\n",
    "        buff.append(word)\n",
    "align_word.append(copy.copy(buff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_word = [[word+'ed' for word in align_word[i] if word is not \"\"]for i in range(26)]\n",
    "d_word = [[word+'d' for word in align_word[i] if word is not \"\"]for i in range(26)]\n",
    "ing_word = [[word+'ing' for word in align_word[i] if word is not \"\"]for i in range (26)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주어진 사전을 이용해서 알파벳순으로 정렬된 list를 새로 만들었습니다.  \n",
    "  \n",
    "예) align_word[0] -> 알파벳 a에 관련된 단어  \n",
    "  \n",
    "이후, ~ed, ~d, ~ing를 구분하기위해  \n",
    "  \n",
    "모든 단어에 ed, d, ing를 붙인 새로운 list를 만들었습니다.  \n",
    "  \n",
    "조금 역발상으로, 단순히 ed가 붙는 단어를 ed를 제거하고 align_word에서 비교하는것 보다 align_word에 ed를 붙여 비교하는것이 더 정확하다고 생각이 들어서 이 방법을 채택했습니다. d 와 ing 또한 마찬가지입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_to_idx(str):\n",
    "    idx = ord(str)-97\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def add_to_dict(dict,str):\n",
    "    dict.setdefault(str, 0)\n",
    "    dict[str] += 1\n",
    "count = 0\n",
    "except_word = ['beau','ootiful','soo','oop','e','evening','beauti','ful']\n",
    "chapter_rome = ['ii','iii','iv','v','vi','vii','viii','ix','x','xi','xii']\n",
    "ed_word=['red','led','tired','hundred', 'indeed', 'speed', 'proceed']\n",
    "empty_word, word_dict, except_list= ['', \"'\"], {}, []\n",
    "\n",
    "for word in words:\n",
    "    \n",
    "#저는 maketrans method에서 '를 제외하고 공백으로 만들었기 때문에, 남아있는 '들을 처리하였습니다.\n",
    "\n",
    "    if word in empty_word+chapter_rome:\n",
    "        continue\n",
    "        \n",
    "#이후, 단어 앞 뒤에 '가 붙어있을 수 있기 때문에(대화형 말투 ex: 'Alice is angry.'에서 /'Alice/is/angry/'/이렇게 나뉘어짐)\n",
    "#처리를 해주었습니다.\n",
    "\n",
    "    if word[0] == \"'\":          #this part becase of ' character in the first line. ex) 'Aliece, 'He ...etc\n",
    "        word = word[1:]\n",
    "    elif word[-1] == \"'\":\n",
    "        word = word[:-1]        #this part because of ' characters can be with in the word.\n",
    "        \n",
    "#em 같은 경우는 'em에서 앞에 '가 사라진 것이고, 검색결과 them의 줄임말이므로 바꾸어주었습니다.\n",
    "\n",
    "    if word == 'em':            #cus upper case already removed ' form the first character, so only em is left in 'em    \n",
    "        add_to_dict(word_dict, 'them')\n",
    "        continue\n",
    "        \n",
    "#tis 또한 it is의 줄임말이기 때문에 나누어 주었습니다.\n",
    "\n",
    "    if word == \"'tis\" or word == 'tis':          #'tis is abbreviation of it is.\n",
    "        add_to_dict(word_dict, 'it')\n",
    "        add_to_dict(word_dict, 'is')\n",
    "        continue\n",
    "        \n",
    "#shan't, won't can't 모두 shall, will, can의 형태가 규칙적이지 않아 위에서 전처리하였습니다.\n",
    "\n",
    "    if word == \"shan't\":        #shan't is abbreviation of shall not\n",
    "        add_to_dict(word_dict, 'shall')\n",
    "        add_to_dict(word_dict, 'not')        \n",
    "        continue\n",
    "    if word == \"won't\":         #won't is abbreviation of will not\n",
    "        add_to_dict(word_dict, 'will')\n",
    "        add_to_dict(word_dict, 'not')        \n",
    "        continue        \n",
    "    if word == \"can't\":         #can't is abbreviation of can not\n",
    "        add_to_dict(word_dict, 'can')\n",
    "        add_to_dict(word_dict, 'not')\n",
    "        continue\n",
    "        \n",
    "#beau---ootiful soo--oop e--e--evening을 처리하기위해, 이 단어들을 예외단어list를 만들어두고, 후에 처리합니다.\n",
    "\n",
    "    if word in except_word:     #declared exception word in upside of code to take care of special case.\n",
    "        except_list.append(word)\n",
    "        continue\n",
    "        \n",
    "#여기서 부터는 not, am, will, are, have가 축약되어있는 단어들을 처리하여줍니다.\n",
    "\n",
    "    if \"'\" in word:             #normal cases include character ' in the word.\n",
    "        if word[-2] == \"'\":     #can be 's, 'd, 't\n",
    "            if word[-1] =='t':  #is going to be (normally) verb + not == verb+n't style\n",
    "                add_to_dict(word_dict, word[:-3])\n",
    "                add_to_dict(word_dict, 'not')\n",
    "                continue\n",
    "            elif word[-1] == 'm':       #to take care of I'm \n",
    "                add_to_dict(word_dict, word[:-2])\n",
    "                add_to_dict(word_dict, 'am')\n",
    "                continue\n",
    "        if word[-3] == \"'\":\n",
    "            if word[-3:] == \"'ll\":      #abbreviation of (something||somebody) will\n",
    "                add_to_dict(word_dict, word[:-3])\n",
    "                add_to_dict(word_dict, 'will')\n",
    "                continue\n",
    "            elif word[-3:] == \"'re\":    #abbreviation of (multiple) are\n",
    "                add_to_dict(word_dict, word[:-3])\n",
    "                add_to_dict(word_dict, 'are')\n",
    "                continue \n",
    "            elif word[-3:] == \"'ve\":    #abbreviation of (something||somebody) have\n",
    "                add_to_dict(word_dict, word[:-3])\n",
    "                add_to_dict(word_dict, 'have')\n",
    "                continue \n",
    "                \n",
    "#어느정도 특수단어들이 끝난 이후에, 사전에 만들어둔 단어list를 통하여 해당 단어가 단어list에 있는지 검사합니다.\n",
    "#과거형과 형용사가 ~ed로 중복되는 경우에는 형용사를 선택하기로 하였습니다.\n",
    "\n",
    "    if word in align_word[alpha_to_idx(word[0])]:  #if the word is in dictionary, add to word_dict\n",
    "        add_to_dict(word_dict, word)\n",
    "        continue\n",
    "\n",
    "#이후 과거형을 다룹니다. 과거형과 형용사가 ~ed로 중복되는 경우에는 형용사를 선택하기로 하였습니다.\n",
    "#for here try to take care of past tens\n",
    "    #~y 단어가 ed를 만나 ied가 되는 특수한 상황에 대해 처리하였습니다.\n",
    "\n",
    "    if \"ied\" in word[-3:]:              #to take care of past tense, special case y->ied\n",
    "        n_word = word[:-3] + 'y'\n",
    "        #tie와 die같은경우에는 예외로 처리하여 주었습니다.\n",
    "        if n_word == 'ty':              #special case of ied past tense. tied, died, ...etc\n",
    "            add_to_dict(word_dict, 'tie')\n",
    "            continue\n",
    "        elif n_word == 'dy':\n",
    "            add_to_dict(word_dict, 'die')\n",
    "            continue\n",
    "        add_to_dict(word_dict, n_word)\n",
    "        continue\n",
    "    \n",
    "    #이후 ed의 형태, ~d 의 형태의 과거형을 다루었습니다.\n",
    "\n",
    "    if 'ed' in word[-2:]:\n",
    "        if word in past_word[alpha_to_idx(word[0])]:   #past tense, word+ed style.\n",
    "            add_to_dict(word_dict, word[:-2])\n",
    "            continue\n",
    "        elif word in d_word[alpha_to_idx(word[0])]:    #this part is for past tense like liked, moved, closed... ~d style\n",
    "            add_to_dict(word_dict,word[:-1])\n",
    "            continue\n",
    "        \n",
    "        #이후 stopped 처럼 마지막 단어가 2번 중복해서 들어가는 단어들에 대해서 다루었습니다.\n",
    "        \n",
    "        elif len(word)>=4 and word[-3] == word[-4]:    #this part is for take care of like stopped, occurred... double letters\n",
    "            add_to_dict(word_dict, word[-3])           #in the past tense.\n",
    "            continue\n",
    "\n",
    "#여기서 부터는 현재진행형을 현재형으로 바꿉니다.\n",
    "#for here try to take care of ~ing style\n",
    "\n",
    "    if 'ing' in word[-3:]:\n",
    "        #우선 예외사항으로 atheling이라는 단어는 왕자를 뜻하는 명사이기에 제거하였습니다.\n",
    "        if word == 'atheling':    #noun of prince\n",
    "            add_to_dict(word_dict, word)\n",
    "            continue\n",
    "        word = word[:-3]\n",
    "        \n",
    "        #ing를 제거하고 곧바로 단어가 완성되는 단어에 대해 처리하였습니다.\n",
    "        \n",
    "        if word in align_word[alpha_to_idx(word[0])]:\n",
    "            add_to_dict(word_dict, word)\n",
    "            continue\n",
    "            \n",
    "        #ing를 더할때 맨 마지막 e를 생략하는 경우를 처리하였습니다.\n",
    "\n",
    "        if word+'e' in align_word[alpha_to_idx(word[0])]: #word-e+ing style\n",
    "            add_to_dict(word_dict, word+'e')\n",
    "            continue\n",
    "        \n",
    "        #나머지 단어들중 마지막 단어가 중복되는 단어들을 처리하였습니다.\n",
    "        \n",
    "        elif word == 'shill': #exception of index -1 and -2 is same\n",
    "            add_to_dict(word_dict, word)\n",
    "            continue\n",
    "        elif word[-1] == word[-2]:   #exception of index -1 and -2 is same\n",
    "            add_to_dict(word_dict,word[:-1])\n",
    "            continue\n",
    "    add_to_dict(word_dict, word)\n",
    "    \n",
    "#여기서부터는 아까 추후 처리를 하려고 빼두었던 단어에 대해서 합성합니다.\n",
    "\n",
    "prev, preprev = '',''\n",
    "for i in except_list:        #to take care of beau ootiful and soo oop and e e evening\n",
    "    if prev+i == 'beauootiful':\n",
    "        add_to_dict(word_dict,'beautiful')\n",
    "    elif prev+i == 'beautiful':\n",
    "        add_to_dict(word_dict,'beautiful')\n",
    "    elif prev+i == 'soooop':\n",
    "        add_to_dict(word_dict,'soup')\n",
    "    elif preprev+prev+i == 'eeevening':\n",
    "        add_to_dict(word_dict,'evening')\n",
    "    elif i == 'evening':\n",
    "        add_to_dict(word_dict,'evening')\n",
    "    prev = i\n",
    "    preprev = prev\n",
    "#위에 언급했다시피 로마숫자 I는 단어에서 제거하기로 하였기에, 하나 낮추어줍니다.\n",
    "word_dict['i'] -= 1        #this is for I(number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1. How many different words are used in the *Alice in Wonderland*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2329\n"
     ]
    }
   ],
   "source": [
    "print(len(word_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. List top 20 frequently used words and their frequencies in the *Alice in Wonderland*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1643), ('and', 872), ('to', 729), ('a', 632), ('she', 544), ('it', 543), ('i', 533), ('of', 514), ('said', 462), ('you', 401), ('alice', 386), ('in', 369), ('was', 368), ('not', 362), ('that', 281), ('as', 263), ('her', 248), ('at', 212), ('on', 193), ('had', 186)]\n"
     ]
    }
   ],
   "source": [
    "word_rank = sorted(word_dict.items(), key = lambda item: item[1], reverse=True)\n",
    "print(word_rank[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3. \n",
    "As children learn to read, there are expectations that their vocabulary will grow. So a child of age 14 is expected to know more words than a child of age 8. When prescribing reading books for a grade, an important question might be “which words in this book are not in the expected vocabulary at this level?”\n",
    "\n",
    "Find the words in the book *Alice in the Wonderland* are not in the vocabulary given in the file  http://openbookproject.net/thinkcs/python/english3e/_downloads/vocab.txt.\n",
    "\n",
    "(어린이가 수준 이상이 되는 단어들을 찾아내는 문제다. 적절한 수준의 단어들로 채워진 단어장에 없으면 적정 수준을 초과한 어려운 단어라는 의미다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"alice's\", 'adventures', 'wonderland', 'lewis', 'carroll', 'alice', 'pictures', 'conversations', 'daisies', 'eyes', 'r', 'ought', 'waistcoat', 'p', 'sides', 'cupboards', 'maps', 'pegs', 'l', 'centre', 'learnt', 'lessons', 'schoolroom', \"that's\", 'words', 'antipathies', \"ma'am\", 'zealand', 'curtsey', 'dinah', 'cats', 'bats', 'ears', \"it's\", 'longer', 'lamps', 'doors', 'g', 'locks', 'inches', 'larger', 'loveliest', 'beds', 'flowers', 'fountains', 'shoulders', 'rules', 'telescopes', 'letters', 'histories', 'beasts', 'friends', 'bleeds', 'sooner', 'flavour', 'legs', \"there's\", 'tears', 'currants', 'makes', 'smaller', 'happens', 'eats', 'curiouser', 'largest', 'shoes', 'stockings', 'dears', 'boots', 'presents', \"one's\", 'esq', 'hearthrug', 'gallons', 'gloves', 'skurry', 'ada', 'goes', 'ringlets', 'mabel', 'sorts', 'knows', \"she's\", \"let's\", 'london', 'paris', 'rome', 'doth', 'hands', 'nile', 'seems', 'claws', 'fishes', 'toys', \"rabbit's\", 'railway', 'machines', 'houses', 'nearer', 'o', \"brother's\", 'inquisitively', 'daresay', 'william', 'ou', 'est', 'ma', 'chatte', \"animal's\", \"you'd\", 'sits', 'paws', 'dogs', 'belongs', 'says', 'pounds', 'kills', 'rats', 'birds', 'animals', 'dodo', 'lory', 'eaglet', 'creatures', 'draggled', 'feathers', 'older', 'ahem', 'driest', 'favoured', 't', 'leaders', 'usurpation', 'edwin', 'morcar', 'earls', 'mercia', 'northumbria', 'stigand', 'canterbury', 'crossly', 'edgar', 'atheling', \"william's\", 'normans', 'remedies', \"what's\", 'shakespeare', 'prizes', 'voices', 'comfits', 'ones', 'c', 'd', \"mouse's\", 'cur', 'others', 'quicker', 'snappishly', \"she'd\", \"dinah's\", 'pretexts', 'footsteps', 'sends', 'ferrets', 'naturedly', 'mary', 'ann', 'housemaid', 'finds', \"i'd\", 'w', 'lest', 'messages', \"they'd\", 'pairs', 'uncorked', 'lips', 'pleasanter', 'rabbits', 'tales', 'apples', 'yer', 'honour', 'sounds', 'arrum', 'fills', 'whispers', 'shrieks', 'frames', 'cartwheels', \"where's\", \"bill's\", \"who's\", 'nay', 'ye', 'comes', 'barrowful', 'pebbles', 'cakes', 'guinea', 'pigs', 'smallest', 'trees', 'feebly', 'charges', \"puppy's\", 'leant', 'n', 'tricks', 'blades', 'hookah', 'sizes', 'chrysalis', 'contemptuously', \"caterpillar's\", 'remarks', 'grey', 'limbs', 'shill', 'tougher', 'suet', 'bones', 'questions', 'taller', 'shorter', 'lefthand', \"head's\", 'tops', 'banks', 'hedges', 'serpents', 'eggs', 'weeks', 'highest', 'changes', 'deepest', 'girls', 'matters', 'branches', 'untwist', 'pieces', 'righthand', 'footman', 'livery', 'knuckles', 'footmen', 'curls', 'reasons', 'uncivil', \"footman's\", 'louder', 'variations', \"he's\", 'cauldron', \"moment's\", 'grins', 'cheshire', 'irons', 'saucepans', 'plates', 'dishes', 'blows', 'faster', 'takes', 'figures', 'sneezes', 'teases', 'pleases', 'b', 'yards', 'puss', 'wider', 'depends', 'hatter', \"dog's\", 'growls', 'wags', 'hatters', 'chimneys', 'dormouse', 'elbows', 'wants', 'riddles', 'ravens', 'desks', 'crumbs', 'tells', \"o'clock\", 'stays', \"hatter's\", 'slightest', 'answers', 'accounts', \"he'd\", 'whiles', 'fellows', 'sisters', 'names', 'elsie', 'lacie', 'tillie', 'treacle', 'sulkily', \"dormouse's\", 'unwillingly', 'begins', 'm', 'traps', 'muchness', 'stupidest', \"everything's\", \"queen's\", 'roses', 'gardeners', 'onions', 'afore', 'faces', 'soldiers', 'corners', 'courtiers', 'couples', 'guests', 'kings', 'queens', 'recognised', 'knave', \"king's\", 'processions', 'rosetree', 'backs', 'places', 'ridges', 'furrows', 'hedgehogs', 'mallets', 'flamingoes', 'arches', 'hedgehog', 'parts', 'players', 'turns', 'attends', \"cat's\", 'likes', 'difficulties', 'arguments', \"executioner's\", \"turtle's\", 'camomile', 'tut', 'closer', \"game's\", \"duchess's\", 'favourite', 'executions', 'gryphon', 'executes', 'hjckrrh', 'educations', 'extras', 'uglification', 'uglify', 'beautify', 'prettier', 'simpleton', 'subjects', 'flappers', 'seaography', 'conger', 'coils', 'quadrille', 'flapper', 'sobs', 'cheeks', 'seals', 'turtles', 'partners', 'lobsters', 'toes', 'forepaws', 'england', 'france', 'dinn', 'mouths', 'soles', 'eels', 'thoughts', 'explanations', 'listeners', 'sluggard', 'eyelids', 'trims', 'buttons', 'editions', 'follows', 'sands', 'tones', 'rises', 'sharks', 'tremulous', 'hm', 'tastes', 'dainties', 'cares', 'pennyworth', \"trial's\", 'faintly', 'tarts', 'chains', 'frontispiece', 'jurors', 'slates', 'neighbour', 'blasts', 'dates', 'shillings', 'pence', 'officers', 'singers', 'denies', 'newspapers', 'attempts', 'jurymen', 'signifies', 'pencils', 'persons', 'oldest', 'verses', \"prisoner's\", 'queerest', \"else's\", 'proves', 'trusts', 'sixpence', 'saves', 'clearer', 'fits', 'inkstand', \"sister's\", 'teacups', \"lizard's\", 'reeds', 'bells', 'cries', 'noises', 'clamour', 'riper', 'sorrows', 'joys']\n",
      "\n",
      "Number of Hard word:  450\n"
     ]
    }
   ],
   "source": [
    "hard_word=[]\n",
    "for word in word_dict:\n",
    "    if word in align_word[alpha_to_idx(word[0])]:\n",
    "        continue\n",
    "    hard_word.append(word)\n",
    "print(hard_word)\n",
    "print(\"\\nNumber of Hard word: \",len(hard_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고사항)  \n",
    "is 와 are가 다른 단어 인거 처럼 daisy와 daisies도 다른 단어로 취급하겠습니다. 단수,복수 구분해주세요 \n",
    "\n",
    "\"'s\" 는 예외가 많습니다. (it has/ it is/ 소유격)\n",
    "- 따라서, it's 를 그냥 새로운 한 단어로 생각해서 풀어주세요.\n",
    "가령 girls' 라고 하면 이것도 새로운 한 단어라고 생각해주세요.\n",
    "- Alice랑 Alice's 각각 새로운 한단어라고 생각하시면 됩니다. 만약, there's 와 there is 가 나왔으면 전자는 1단어 후자는 2단어 입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
